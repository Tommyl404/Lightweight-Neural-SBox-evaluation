{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjUr2IqDZXHU"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "cxtHUUoa02MT",
        "outputId": "2f41ac83-4b23-443d-8f4d-295007b80e98"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from get_NN_dataset import CustomDataset\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 1.  File sanity‑check\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "filename = \"10_Thousand_samples_LP_DEG_SAC.pt\"\n",
        "if not os.path.isfile(filename) or os.path.getsize(filename) == 0:\n",
        "    raise FileNotFoundError(f\"Dataset file '{filename}' is missing or empty.\")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 2.  Load (explicitly allow full pickle)\n",
        "#     • weights_only=False  restores the pre‑2.6 behaviour.\n",
        "#     • map_location='cpu'  keeps everything on CPU by default.\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "filename = \"10_Thousand_samples_LP_DEG_SAC.pt\"\n",
        "dataset = torch.load(filename, weights_only=False, map_location=\"cpu\")\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 3.  Normalise so we always have something index‑able\n",
        "#     * If the object already acts like a Dataset (has __getitem__)\n",
        "#       we leave it untouched.\n",
        "#     * If it’s a dict with plain tensors we wrap it in TensorDataset.\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "if isinstance(dataset, dict):\n",
        "    if {\"data\", \"labels\"} <= dataset.keys():\n",
        "        data_tensor   = dataset[\"data\"]\n",
        "        labels_tensor = dataset[\"labels\"]\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Expected keys {{'data', 'labels'}}, got {list(dataset.keys())}\"\n",
        "        )\n",
        "    # Guarantee a channel dim: (N, H, W) → (N, 1, H, W)\n",
        "    if data_tensor.ndim == 3:\n",
        "        data_tensor = data_tensor.unsqueeze(1)\n",
        "    dataset = torch.utils.data.TensorDataset(data_tensor, labels_tensor)\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 4.  Quick inspection\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "print(\"Samples :\", len(dataset))\n",
        "print(\"One item :\", dataset[0][0].shape, type(dataset[0][1]))\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 5.  Visualise a single sample\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "img, lbl = dataset[0]\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(img.reshape([8,4]).squeeze().numpy(), cmap=\"gray\", aspect=\"auto\")\n",
        "plt.title(f\"Label: {int(lbl)}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "# 6.  Visualise the first 10 samples as a heat‑map grid\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "rows, cols = 2, 5\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(12, 5))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(rows * cols):\n",
        "    img, lbl = dataset[i]\n",
        "    axes[i].imshow(img.squeeze().numpy(), cmap=\"hot\", aspect=\"auto\")\n",
        "    axes[i].set_title(f\"Label: {int(lbl)}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "OFdpOlCRZnxw",
        "outputId": "44b4761c-2eaa-4c69-b152-32fcc022504f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "filename = \"/content/sample_data/10_Thousand_samples_LP_DEG_SAC.pt\"\n",
        "\n",
        "if not os.path.isfile(filename) or os.path.getsize(filename) == 0:\n",
        "    raise FileNotFoundError(f\"Dataset file '{filename}' is missing or empty.\")\n",
        "\n",
        "# 1. Load without the new‑format flag\n",
        "dataset = torch.load(filename)          # <= remove weights_only\n",
        "\n",
        "# 2. Inspect what we actually got\n",
        "print(\"Loaded object type:\", type(dataset))\n",
        "\n",
        "# If it’s a dict with ‘data’ and ‘labels’ tensors:\n",
        "if isinstance(dataset, dict) and {'data', 'labels'} <= dataset.keys():\n",
        "    data_tensor, label_tensor = dataset['data'], dataset['labels']\n",
        "    print(\"Data shape:\", data_tensor.shape, \"Labels shape:\", label_tensor.shape)\n",
        "\n",
        "    # Visualise the first sample\n",
        "    img = data_tensor[0]\n",
        "    lbl = int(label_tensor[0])          # makes sure it’s a Python int\n",
        "else:\n",
        "    # Assume it’s already a list‑like of (img, label) pairs\n",
        "    img, lbl = dataset[0]\n",
        "    if isinstance(lbl, torch.Tensor):\n",
        "        lbl = int(lbl)\n",
        "\n",
        "# 3. Plot\n",
        "plt.figure()\n",
        "plt.imshow(img.squeeze(), cmap='gray', aspect='auto')  # squeeze in case there’s a 1‑channel dim\n",
        "plt.title(f\"Label: {lbl}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl9uIKXjc5ia",
        "outputId": "c3e83947-2902-490b-e7f4-35558f4235b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 184474, Train samples: 147579, Test samples: 36895\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (64x9 and 256x256)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     79\u001b[39m x, y = x.to(device), y.to(device)\n\u001b[32m     81\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m loss = loss_fn(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, y)\n\u001b[32m     83\u001b[39m loss.backward()\n\u001b[32m     84\u001b[39m optimizer.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mBinaryMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m     46\u001b[39m   temp = \u001b[38;5;28mself\u001b[39m.flatten(x)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m   temp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m   temp = \u001b[38;5;28mself\u001b[39m.activation(temp)\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outl(temp)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (64x9 and 256x256)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import  transforms # ,datasets\n",
        "from get_NN_dataset import CustomDataset, generate_dataset\n",
        "\n",
        "# ---------- Data ----------\n",
        "class ToBinaryTensor:\n",
        "    def __call__(self, img):\n",
        "        t = transforms.functional.to_tensor(img)      # [0,1]\n",
        "        return torch.where(t > 0.5, 1.0, -1.0)        # {-1, +1}\n",
        "\n",
        "filename = \"new_10_Million_samples_LP_DEG_SAC.pt\"\n",
        "dataset = torch.load(filename, weights_only=False, map_location=\"cpu\")\n",
        "\n",
        "\n",
        "dataset.data = torch.stack(dataset.data)  # Convert list of tensors to a single tensor\n",
        "dataset.data = torch.stack(dataset.labels)  # Convert list of tensors to a single tensor\n",
        "\n",
        "transform = transforms.Compose([ToBinaryTensor()])\n",
        "# Set your desired train-test ratio (e.g., 0.8 for 80% train, 20% test)\n",
        "train_test_ratio = 0.8\n",
        "\n",
        "# Calculate sizes\n",
        "total_size = len(dataset)  # Assuming dataset.data is a tensor of shape (N, C, H, W)\n",
        "train_size = int(total_size * train_test_ratio)\n",
        "test_size = total_size - train_size\n",
        "print(f\"Total samples: {total_size}, Train samples: {train_size}, Test samples: {test_size}\")\n",
        "# Split the dataset\n",
        "train_ds, test_ds = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=256)\n",
        "\n",
        "# ---------- Model ----------\n",
        "class BinaryMLP(nn.Module):\n",
        "    def __init__(self, hidden_dim: int = 256):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.inl = nn.Linear(256, hidden_dim) # hidden layer\n",
        "        self.activation = nn.ReLU()\n",
        "        self.outl = nn.Linear(hidden_dim, 9)   # output\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "          temp = self.flatten(x)\n",
        "          temp = self.inl(temp)\n",
        "          temp = self.activation(temp)\n",
        "          return self.outl(temp)\n",
        "        else:\n",
        "          temp = self.flatten(x)\n",
        "          temp = torch.where(temp > 0, 1.0, -1.0)\n",
        "          temp = self.inl(temp)\n",
        "          temp = self.activation(temp)\n",
        "          temp = torch.where(temp > 0, 1.0, -1.0)\n",
        "          return self.outl(temp)\n",
        "\n",
        "model = BinaryMLP(hidden_dim=256).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Training loop ----------\n",
        "loss_fn   = nn.CrossEntropyLoss()  # works on raw logits\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "device    = next(model.parameters()).device\n",
        "\n",
        "def accuracy(loader):\n",
        "    correct = total = 0\n",
        "    for x, y in loader:\n",
        "        logits = model(x.to(device))\n",
        "        pred   = logits.argmax(dim=1)\n",
        "        correct += (pred.cpu() == y).sum().item()\n",
        "        total   += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in train_dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * y.size(0)\n",
        "\n",
        "    train_acc = accuracy(train_dl)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_acc  = accuracy(test_dl)\n",
        "    print(f\"Epoch {epoch}: \"\n",
        "          f\"loss={running_loss/len(train_ds):.4f}  \"\n",
        "          f\"train_acc={train_acc:.3%}  test_acc={test_acc:.3%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjBE68HI96Ud",
        "outputId": "1523bf59-97c0-4666-d9cc-13f7b9e7581e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.33MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 187kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.09MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss=0.9492  train_acc=86.780%  test_acc=87.540%\n",
            "Epoch 2: loss=0.4181  train_acc=89.922%  test_acc=90.150%\n",
            "Epoch 3: loss=0.3321  train_acc=91.327%  test_acc=91.400%\n",
            "Epoch 4: loss=0.2900  train_acc=92.228%  test_acc=91.900%\n",
            "Epoch 5: loss=0.2614  train_acc=92.932%  test_acc=92.650%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ---------- Data ----------\n",
        "class ToBinaryTensor:\n",
        "    def __call__(self, img):\n",
        "        t = transforms.functional.to_tensor(img)      # [0,1]\n",
        "        return torch.where(t > 0.5, 1.0, -1.0)        # {-1, +1}\n",
        "\n",
        "transform = transforms.Compose([ToBinaryTensor()])\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=256)\n",
        "\n",
        "# ---------- Model ----------\n",
        "class Binarize(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return torch.where(input > 0, 1.0, -1.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.clamp(-1,1)\n",
        "\n",
        "class BinLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(BinLinear, self).__init__()\n",
        "        # Define parameters (weights & bias for example)\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bn = nn.BatchNorm1d(num_features=out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Custom operation: simple linear layer here\n",
        "        preBn = Binarize.apply(x) @ Binarize.apply(self.weight.t())\n",
        "        postBn = self.bn(preBn)\n",
        "        return torch.nn.functional.hardtanh(postBn)\n",
        "\n",
        "class CustomBinaryMLP(nn.Module):\n",
        "    def __init__(self, hidden_dim: int = 256):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()              # 28×28 → 784\n",
        "        self.inl = BinLinear(784, hidden_dim) # hidden layer\n",
        "        self.activation = nn.ReLU()\n",
        "        self.outl = nn.Linear(hidden_dim, 10)   # output\n",
        "\n",
        "    def forward(self, x):\n",
        "        temp = self.flatten(x)\n",
        "        temp = self.activation(self.inl(temp))\n",
        "        return self.outl(temp)\n",
        "\n",
        "model = CustomBinaryMLP(hidden_dim=256).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Training loop ----------\n",
        "loss_fn   = nn.CrossEntropyLoss()  # works on raw logits\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "device    = next(model.parameters()).device\n",
        "\n",
        "def accuracy(loader):\n",
        "    correct = total = 0\n",
        "    for x, y in loader:\n",
        "        logits = model(x.to(device))\n",
        "        pred   = logits.argmax(dim=1)\n",
        "        correct += (pred.cpu() == y).sum().item()\n",
        "        total   += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in train_dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * y.size(0)\n",
        "\n",
        "    train_acc = accuracy(train_dl)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_acc  = accuracy(test_dl)\n",
        "    print(f\"Epoch {epoch}: \"\n",
        "          f\"loss={running_loss/len(train_ds):.4f}  \"\n",
        "          f\"train_acc={train_acc:.3%}  test_acc={test_acc:.3%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGHrpkcSKFZ8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ---------- Data ----------\n",
        "class ToBinaryTensor:\n",
        "    def __call__(self, img):\n",
        "        t = transforms.functional.to_tensor(img)      # [0,1]\n",
        "        return torch.where(t > 0.5, 1.0, -1.0)        # {-1, +1}\n",
        "\n",
        "transform = transforms.Compose([ToBinaryTensor()])\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_dl  = DataLoader(test_ds,  batch_size=256)\n",
        "\n",
        "# ---------- Model ----------\n",
        "class Binarize(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        return torch.where(input > 0, 1.0, -1.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.clamp(-1,1)\n",
        "\n",
        "class BinLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(BinLinear, self).__init__()\n",
        "        # Define parameters (weights & bias for example)\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        self.bn = nn.BatchNorm1d(num_features=out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Custom operation: simple linear layer here\n",
        "        preBn = Binarize.apply(x) @ Binarize.apply(self.weight.t())\n",
        "        postBn = self.bn(preBn)\n",
        "        return torch.nn.functional.hardtanh(postBn)\n",
        "\n",
        "class CustomBinaryMLP(nn.Module):\n",
        "    def __init__(self, hidden_dim: int = 256):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()              # 28×28 → 784\n",
        "        self.inl = BinLinear(784, hidden_dim) # hidden layer\n",
        "        self.activation = nn.ReLU()\n",
        "        self.outl = nn.Linear(hidden_dim, 10)   # output\n",
        "\n",
        "    def forward(self, x):\n",
        "        temp = self.flatten(x)\n",
        "        temp = self.activation(self.inl(temp))\n",
        "        return self.outl(temp)\n",
        "\n",
        "model = CustomBinaryMLP(hidden_dim=256).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Training loop ----------\n",
        "loss_fn   = nn.CrossEntropyLoss()  # works on raw logits\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "device    = next(model.parameters()).device\n",
        "\n",
        "def accuracy(loader):\n",
        "    correct = total = 0\n",
        "    for x, y in loader:\n",
        "        logits = model(x.to(device))\n",
        "        pred   = logits.argmax(dim=1)\n",
        "        correct += (pred.cpu() == y).sum().item()\n",
        "        total   += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for x, y in train_dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(model(x), y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * y.size(0)\n",
        "\n",
        "    train_acc = accuracy(train_dl)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_acc  = accuracy(test_dl)\n",
        "    print(f\"Epoch {epoch}: \"\n",
        "          f\"loss={running_loss/len(train_ds):.4f}  \"\n",
        "          f\"train_acc={train_acc:.3%}  test_acc={test_acc:.3%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Ym_4uod5DB"
      },
      "source": [
        "* generate dataset\n",
        "* output bits are desicion points - for example LP is 4 different bits for 4 different threshold.\n",
        "* start from the simplest network\n",
        "\n",
        "ideas:\n",
        "metrics are LP, DP, SAC.\n",
        "LP:\n",
        "∑_x (-1)^(f(x)⊕u⋅x\n",
        "DP: max ddt\n",
        "SAC:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e302e05c",
        "outputId": "c792c84b-f8b5-4cc4-8af9-2804cad392a7"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/sample_data/10_Million_samples_LP_DEG_SAC.pt\"\n",
        "try:\n",
        "    with open(filename, 'rb') as f:\n",
        "        # Read the first 100 bytes\n",
        "        header = f.read(100)\n",
        "    print(\"First 100 bytes of the file:\")\n",
        "    print(header)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
